<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Role of Machine Learning and Computation in MEMENTO by Vaibhav Jain</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Ink+Free&family=Roboto+Mono:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <div class="project-info">
            <h1>Role of Machine Learning and Computation in<br>
                <span class="memento-text">MEMENTO</span><span class="author-credit">by Vaibhav Jain</span>
            </h1>
            <p class="course-title"><a href="https://www.arch.columbia.edu/courses/10943-5078" target="_blank">Exploring Urban Data with Machine Learning</a></p>
            <p class="advisor">by <a href="https://www.arch.columbia.edu/faculty/5512-jonathan-stiles" target="_blank">Jonathan E. Stiles</a> in Spring 2025</p>
            <p class="program"><a href="https://www.arch.columbia.edu/programs/15-m-s-computational-design-practices" target="_blank">Computation Design Practices 2024-2025</a></p>
            <p class="college"><a href="https://www.arch.columbia.edu/" target="_blank">Graduate School of Architecture, Planning and Preservation, Columbia University</a></p>
        </div>
    </header>

    <section class="qr-row">
        <div class="qr-item">
            <a href="https://0209vaibhav.github.io/Machine-Learning_MEMENTO/" target="_blank">
                <img src="/data/qr-codes/MEMENTO-machine learning-Vaibhav Jain.png" alt="MEMENTO Machine Learning QR">
            </a>
        </div>
        <div class="qr-item">
            <a href="https://0209vaibhav.github.io/Memento/" target="_blank">
                <img src="/data/qr-codes/MEMENTO-platform-Vaibhav Jain.png" alt="MEMENTO Platform QR">
            </a>
        </div>
        <div class="qr-item">
            <a href="https://gsapp-cdp.github.io/archive/projects/2025/memento/" target="_blank">
                <img src="/data/qr-codes/MEMENTO-project documentation-Vaibhav Jain.png" alt="MEMENTO Project Documentation QR">
            </a>
        </div>
    </section>

    <nav class="article-nav">
        <a href="#overview-section" class="active">Overview</a>
        <a href="#introduction-section">Introduction</a>
        <a href="#pipeline-section">Pipeline</a>
        <a href="#detailed-pipeline-section">Detailed Pipeline</a>
    </nav>
    <section class="overview-section" id="overview-section">
        <h2>1. Overview</h2>
        <h3>Overview of the Computation tools, methods and Machine Learning Pipeline in MEMENTO</h3>
        <p>The Machine Learning pipeline for public mementos in MEMENTO is designed to automate the classification and tagging of public content sourced from platforms such as Secret NYC, Reddit, NYC Bucket List, Newsbreak, and more. The objective is to replace rule-based keyword matching with a robust multi-label classification model that leverages existing user-generated mementos as training data.</p>
        <p>The pipeline consists of three primary models â€” Category Classification, Tag Prediction, and Duration Estimation â€” each trained using supervised learning techniques. Logistic Regression with One-vs-Rest strategy and Random Forest classifiers are employed to predict relevant categories and multiple tags, while Decision Trees handle ordinal duration estimation. Text data undergoes preprocessing, including tokenization, stop word removal, and TF-IDF vectorization to convert descriptions into feature vectors suitable for model training.</p>
        <p>By implementing this ML pipeline, MEMENTO enhances the consistency and accuracy of content classification, enabling the platform to transform unstructured public content into structured, contextually enriched mementos that align with its existing taxonomy.</p>
    </section>
    <section class="introduction-section" id="introduction-section">
        <h2>Introduction</h2>
        <h3>1.1 What is MEMENTO?</h3>
        <p>Not just a map of locations â€”<br>
but a real-time playground of urban experiences.<br>
To resist oblivion commutes,<br>
and embrace engaging odyssey journeys.<br>
This is MEMENTO.</p>
        <img src="data/cover 2.png" alt="MEMENTO Cover" class="hero-image">
        <p>MEMENTO is a real-time platform that captures urban experiences happening across the city, aiming to prevent people from drifting into oblivion (the state of being unaware or unconscious of what is happening) and instead transforming those moments into engaging odysseys (a long and eventful or adventurous journey or experience).</p>
        <p>Unlike conventional platforms, MEMENTO invites users to look beyond the map â€” to notice, witness, interact, engage, record, react, and reflect on urban experiences as physical mementos, rather than merely experiencing them through virtual screens.</p>
        <img src="data/mementos-categories,tags duration.png" alt="MEMENTO - the platform" class="section-image">
        <p>It empowers users to discover, capture, and engage with the mementos around them during their commutes, turning everyday journeys into moments of exploration, creation, and interaction.</p>
        <img src="data/core action diagram.svg" alt="MEMENTO - the platform" class="section-image">
        <p>MEMENTO serves as an interaction, intersection, and interplay between the city, its people, and their experiences â€” a platform:<br>
            By the people and the city,<br>
For the people and the city,<br>
Of the people and the city.</p>
<img src="data/for by of copy.png" alt="MEMENTO - the platform" class="section-image">
    </section>


    <section class="pipeline-section" id="pipeline-section">
        <h2>Pipeline Architecture Overview</h2>
        <p>The MEMENTO ML pipeline is designed as a modular, five-step system that transforms raw public content into well-categorized, ML-enhanced mementos. Each step in the pipeline serves a specific purpose and contributes to the overall goal of automated content classification and enrichment.</p>

        <div class="pipeline-diagram">
            <div class="pipeline-steps-container">
                <div class="pipeline-step" data-step="1">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>ğŸ”„ Data Processing</h4>
                        <p>Transform raw user mementos into standardized datasets</p>
                    </div>
                </div>
                <div class="pipeline-arrow">â†’</div>
                <div class="pipeline-step" data-step="2">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>âš™ï¸ Data Preparation</h4>
                        <p>Prepare data for model training</p>
                    </div>
                </div>
                <div class="pipeline-arrow">â†’</div>
                <div class="pipeline-step" data-step="3">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>ğŸ§  Model Training</h4>
                        <p>Train specialized classification models</p>
                    </div>
                </div>
                <div class="pipeline-arrow">â†’</div>
                <div class="pipeline-step" data-step="4">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>ğŸŒ Data Scraping</h4>
                        <p>Collect and process public content</p>
                    </div>
                </div>
                <div class="pipeline-arrow">â†’</div>
                <div class="pipeline-step" data-step="5">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h4>âœ¨ Processing & Classification</h4>
                        <p>Apply models to classify content</p>
            </div>
                </div>
            </div>
            <div class="pipeline-details">
                <div class="step-details" data-step="1">
                    <h3>ğŸ”„ Step 1: Data Processing</h3>
                    <p>The initial step focuses on transforming raw user mementos into a standardized dataset suitable for machine learning. This step includes:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>ğŸ“¥ 1. Data Collection and Standardization</h4>
                            <ul>
                                <li>Reading raw memento data from JSON files</li>
                                <li>Standardizing field names and data formats</li>
                                <li>Handling missing values and data inconsistencies</li>
                                <li>Implementing data validation checks</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ§¬ 2. Feature Extraction</h4>
                            <ul>
                                <li>Processing text fields (title, description, location)</li>
                                <li>Extracting temporal information</li>
                                <li>Standardizing date formats</li>
                                <li>Handling special characters and formatting</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>âœ… 3. Quality Control</h4>
                            <ul>
                                <li>Validating data integrity</li>
                                <li>Checking for required fields</li>
                                <li>Ensuring consistent data types</li>
                                <li>Generating processing statistics</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="2">
                    <h3>âš™ï¸ Step 2: Data Preparation</h3>
                    <p>This step prepares the processed data for model training by:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>ğŸª“ 1. Data Splitting</h4>
                            <ul>
                                <li>Creating training and validation sets</li>
                                <li>Maintaining balanced category distribution</li>
                                <li>Preserving data integrity</li>
                                <li>Implementing stratified sampling</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ› ï¸ 2. Feature Engineering</h4>
                            <ul>
                                <li>Creating text feature matrices</li>
                                <li>Implementing TF-IDF vectorization</li>
                                <li>Handling categorical variables</li>
                                <li>Preparing label encoders</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ§¹ 3. Data Preprocessing</h4>
                            <ul>
                                <li>Text cleaning and normalization</li>
                                <li>Feature scaling</li>
                                <li>Handling missing values</li>
                                <li>Preparing multi-label formats</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="3">
                    <h3>ğŸ§  Step 3: Model Training</h3>
                    <p>The pipeline implements three specialized models for different classification tasks:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>ğŸŒ² 1. Category Classification Model</h4>
                            <ul>
                                <li>Type: Random Forest Classifier</li>
                                <li>Features: Title, description, location</li>
                                <li>Output: Category predictions with confidence scores</li>
                                <li>Parameters: n_estimators=100, max_depth=10</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ·ï¸ 2. Tags Prediction Model</h4>
                            <ul>
                                <li>Type: Multi-label Classification</li>
                                <li>Features: Title, description, location</li>
                                <li>Output: Multiple tag predictions</li>
                                <li>Parameters: threshold=0.3</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>â³ 3. Duration Estimation Model</h4>
                            <ul>
                                <li>Type: Decision Tree Classifier</li>
                                <li>Features: Title, description, location</li>
                                <li>Output: Duration predictions</li>
                                <li>Parameters: max_depth=5</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="4">
                    <h3>ğŸŒ Step 4: Data Scraping</h3>
                    <p>This step collects and processes public content:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>ğŸŒ 1. Web Scraping</h4>
                            <ul>
                                <li>Target: Secret NYC website</li>
                                <li>Content types: Articles, events, locations</li>
                                <li>Extraction methods: BeautifulSoup4</li>
                                <li>Rate limiting and error handling</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ“ 2. Content Processing</h4>
                            <ul>
                                <li>Text extraction and cleaning</li>
                                <li>Date parsing and standardization</li>
                                <li>Location extraction</li>
                                <li>Duration estimation</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ” 3. Data Validation</h4>
                            <ul>
                                <li>Content quality checks</li>
                                <li>Required field validation</li>
                                <li>Format standardization</li>
                                <li>Error logging</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="5">
                    <h3>âœ¨ Step 5: Data Processing and Classification</h3>
                    <p>The final step applies the trained models to classify scraped content:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>ğŸ¤– 1. Model Application</h4>
                            <ul>
                                <li>Loading trained models</li>
                                <li>Text preprocessing</li>
                                <li>Feature extraction</li>
                                <li>Prediction generation</li>
                            </ul>
            </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ›¡ï¸ 2. Quality Control</h4>
                            <ul>
                                <li>Confidence threshold checks</li>
                                <li>Prediction validation</li>
                                <li>Error handling</li>
                                <li>Report generation</li>
            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>ğŸ“¦ 3. Output Generation</h4>
                            <ul>
                                <li>Creating processed mementos</li>
                                <li>Adding predictions and confidence scores</li>
                                <li>Generating processing reports</li>
                                <li>Saving results in multiple formats</li>
            </ul>
                        </div>
                    </div>
                </div>
                </div>
            </div>

        

    <section class="detailed-pipeline-section" id="detailed-pipeline-section">
        <h2>Detailed Pipeline Implementation and Methodology</h2>
        <h3>Overview</h3>
        <p>The MEMENTO ML pipeline is implemented as a modular Python system, with each step building upon the previous one to transform raw content into ML-enhanced mementos. This section provides a detailed technical breakdown of each step, including implementation details, code examples, and data flow.</p>

        <hr>
        <h2>Step 1: Data Loading and Preparation <span style="font-size:0.7em; font-weight:normal;">(step1_data_loader.py)</span></h2>
        <h3>Overview</h3>
        <p>The first step of the MEMENTO ML pipeline focuses on loading user mementos from Firebase and preparing them for machine learning training. This step is crucial for establishing the foundation of our ML pipeline by ensuring data quality and proper formatting.</p>
        <h3>Purpose</h3>
        <ul>
            <li>Load user mementos from Firebase</li>
            <li>Process and standardize the data</li>
            <li>Prepare features for ML training</li>
            <li>Save processed data for subsequent steps</li>
        </ul>
        <h3>Implementation Details</h3>
        <h4>1. Class Structure and Initialization</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">class MementoDataLoader:
    def __init__(self, 
                 categories_path: str = None,
                 tags_path: str = None,
                 durations_path: str = None,
                 firebase_credentials_path: str = None):
        self.categories = {}
        self.tags = {}
        self.durations = {}
        self.db = None
        self.lemmatizer = WordNetLemmatizer()
        self.stop_words = set(stopwords.words('english'))
</code></pre>
        <strong>Components:</strong>
        <ul>
            <li>Categories dictionary: Stores category mappings</li>
            <li>Tags dictionary: Stores tag information</li>
            <li>Durations dictionary: Stores duration configurations</li>
            <li>Firebase database connection</li>
            <li>NLTK components for text processing</li>
        </ul>
        <strong>Dependencies:</strong>
        <ul>
            <li>NLTK (Natural Language Toolkit)</li>
            <li>Firebase Admin SDK</li>
            <li>Pandas</li>
            <li>Logging module</li>
        </ul>
        <h4>2. Metadata Loading</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def load_categories(self, categories_path: str):
    logging.info(f"Loading categories from {categories_path}")
    with open(categories_path, "r", encoding="utf-8") as f:
        self.categories = json.load(f)
    logging.info(f"Loaded {len(self.categories)} categories")

def load_tags(self, tags_path: str) -> List[str]:
    logging.info(f"Loading tags from {tags_path}")
    with open(tags_path, "r", encoding="utf-8") as f:
        tags_data = json.load(f)
        tags = [tag["name"] for tag in tags_data]
    logging.info(f"Loaded {len(tags)} tags")
    return tags

def load_durations(self, durations_path: str):
    logging.info(f"Loading durations from {durations_path}")
    with open(durations_path, "r", encoding="utf-8") as f:
        self.durations = json.load(f)
    logging.info(f"Loaded {len(self.durations)} durations")
</code></pre>
        <strong>Process:</strong>
        <ol>
            <li>Read JSON files containing metadata</li>
            <li>Validate file format and content</li>
            <li>Store metadata in class attributes</li>
            <li>Log loading statistics</li>
        </ol>
        <strong>Input Files:</strong>
        <ul>
            <li><code>memento_categories.json</code>: Category definitions</li>
            <li><code>memento_tags.json</code>: Tag definitions</li>
            <li><code>memento_durations.json</code>: Duration definitions</li>
        </ul>
        <div class="json-scroll-lists-wrapper">
            <div class="json-scroll-list">
                <h4>Categories <span style="font-size:0.9em; color:#888;">(memento_categories.json)</span></h4>
                <ul>
                    <li>ğŸ›ï¸ Architecture <span class="json-id">(architecture)</span></li>
                    <li>ğŸŒ¿ Urban Nature <span class="json-id">(urban-nature)</span></li>
                    <li>ğŸŒˆ Sky & Weather <span class="json-id">(sky-weather)</span></li>
                    <li>ğŸ­ Cultural Spotlight <span class="json-id">(cultural)</span></li>
                    <li>ğŸ§ Mood & Music <span class="json-id">(mood-music)</span></li>
                    <li>ğŸ¾ Creature Sighting <span class="json-id">(creature)</span></li>
                    <li>ğŸ´ Street Food <span class="json-id">(street-food)</span></li>
                    <li>ğŸ‘¥ Social Gathering <span class="json-id">(social)</span></li>
                    <li>âš½ Sport in Action <span class="json-id">(sport)</span></li>
                    <li>âœï¸ Poetic Reflection <span class="json-id">(poetic)</span></li>
                    <li>ğŸ’¡ Urban Folklore <span class="json-id">(folklore)</span></li>
                    <li>ğŸ—ï¸ City in Transition <span class="json-id">(transition)</span></li>
                    <li>âš ï¸ Unpleasant Spot <span class="json-id">(unpleasant)</span></li>
                    <li>ğŸ‘¥ Public Event <span class="json-id">(public-event)</span></li>
                    <li>ğŸ›ï¸ Pop-Up Culture <span class="json-id">(popup-culture)</span></li>
                    <li>ğŸ® Play & Participation <span class="json-id">(playful)</span></li>
                    <li>ğŸ“ City Learning <span class="json-id">(learning)</span></li>
                    <li>ğŸ•Šï¸ Tranquil Corners <span class="json-id">(tranquil)</span></li>
                    <li>ğŸ§ª Experimental Urbanism <span class="json-id">(experimental)</span></li>
                    <li>ğŸ—‚ï¸ Other <span class="json-id">(other)</span></li>
                </ul>
            </div>
            <div class="json-scroll-list">
                <h4>Tags <span style="font-size:0.9em; color:#888;">(memento_tags.json)</span></h4>
                <ul>
                    <li>ğŸŒ€ Ephemeral <span class="json-id">(ephemeral)</span></li>
                    <li>ğŸ“ Unmapped <span class="json-id">(unmapped)</span></li>
                    <li>ğŸ§¬ Niche/Cult <span class="json-id">(niche)</span></li>
                    <li>ğŸ’« Emotionally Charged <span class="json-id">(emotional)</span></li>
                    <li>ğŸ•µï¸ Hidden Gem <span class="json-id">(hidden)</span></li>
                    <li>ğŸ­ Unexpected Encounter <span class="json-id">(unexpected)</span></li>
                    <li>ğŸª Reflective <span class="json-id">(reflective)</span></li>
                    <li>ğŸ’” Unpleasant Truth <span class="json-id">(unpleasant)</span></li>
                    <li>â³ Once-in-a-While <span class="json-id">(rare)</span></li>
                    <li>ğŸ”„ Recurring Ritual <span class="json-id">(recurring)</span></li>
                    <li>ğŸ§ƒ Local Flavor <span class="json-id">(local)</span></li>
                    <li>ğŸ’ƒ Performative <span class="json-id">(performative)</span></li>
                    <li>ğŸ‘€ Blink and You Miss It <span class="json-id">(blink)</span></li>
                    <li>ğŸ§² Highly Social <span class="json-id">(social-heavy)</span></li>
                    <li>ğŸŒƒ Nightlife Pulse <span class="json-id">(nightlife)</span></li>
                    <li>ğŸ§³ Touristy Yet Fun <span class="json-id">(touristy)</span></li>
                    <li>ğŸ§¼ Over-Polished <span class="json-id">(clean-cut)</span></li>
                    <li>ğŸ£ First-Time Friendly <span class="json-id">(beginner)</span></li>
                    <li>ğŸ™ï¸ Iconic Landmark <span class="json-id">(iconic)</span></li>
                    <li>ğŸ—‚ï¸ Other <span class="json-id">(other)</span></li>
                </ul>
            </div>
            <div class="json-scroll-list">
                <h4>Durations <span style="font-size:0.9em; color:#888;">(memento_durations.json)</span></h4>
                <ul>
                    <li>âš¡ 15 Minutes <span class="json-id">(15min)</span></li>
                    <li>â±ï¸ 1 Hour <span class="json-id">(1hr)</span></li>
                    <li>âŒ› 1-3 Hours <span class="json-id">(1-3hrs)</span></li>
                    <li>ğŸŒ… 3-6 Hours <span class="json-id">(3-6hrs)</span></li>
                    <li>ğŸŒ 6-12 Hours <span class="json-id">(6-12hrs)</span></li>
                    <li>ğŸŒ™ A Day <span class="json-id">(24hrs)</span></li>
                    <li>ğŸ“… A Week <span class="json-id">(1-week)</span></li>
                    <li>ğŸ“† A Month <span class="json-id">(1-month)</span></li>
                    <li>ğŸ”„ A Season <span class="json-id">(1-season)</span></li>
                    <li>ğŸ“… A Year <span class="json-id">(1-year)</span></li>
                    <li>â™¾ï¸ Eternal <span class="json-id">(eternal)</span></li>
                    <li>ğŸ—‚ï¸ Other <span class="json-id">(other)</span></li>
                </ul>
            </div>
        </div>
        <h4>3. Firebase Integration</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def _initialize_firebase(self):
    try:
        cred = credentials.Certificate(self.firebase_credentials_path)
        firebase_admin.initialize_app(cred)
        self.db = firestore.client()
        logging.info("Firebase initialized successfully")
    except Exception as e:
        logging.error(f"Failed to initialize Firebase: {e}")

def load_from_firebase(self, limit=1000):
    try:
        logging.info(f"Loading up to {limit} mementos from Firebase")
        mementos_ref = self.db.collection("mementos").limit(limit)
        mementos = mementos_ref.get()
        
        memento_list = []
        for doc in mementos:
            memento_data = doc.to_dict()
            memento_data['id'] = doc.id
            memento_list.append(memento_data)
        
        return pd.DataFrame(memento_list)
    except Exception as e:
        logging.error(f"Error loading mementos from Firebase: {str(e)}")
        raise
</code></pre>
        <strong>Features:</strong>
        <ul>
            <li>Secure credential management</li>
            <li>Error handling and logging</li>
            <li>Connection state tracking</li>
            <li>Data retrieval with limit</li>
            </ul>
        <h4>4. Text Preprocessing</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def _preprocess_text(self, text: str) -> str:
    if not isinstance(text, str):
        text = str(text)
    
    # Convert to lowercase
    text = text.lower()
    
    # Remove special characters and digits
    text = re.sub(r'[^a-z\s]', ' ', text)
    
    # Remove extra whitespace
    text = ' '.join(text.split())
    
    return text
</code></pre>
        <strong>Processing Steps:</strong>
        <ol>
            <li>Type conversion to string</li>
            <li>Lowercase conversion</li>
            <li>Special character removal</li>
            <li>Whitespace normalization</li>
        </ol>
        <h4>5. Feature Extraction</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def _extract_text_for_ml(self, memento: Dict) -> str:
    text_parts = []
    
    # Add name with higher weight (repeat 3 times)
    name = memento.get('name', '')
    text_parts.extend([name] * 3)
    
    # Add description
    description = memento.get('description', '')
    text_parts.append(description)
    
    # Add location name if available
    location = memento.get('location', {})
    if isinstance(location, dict):
        location_str = str(location)
        text_parts.append(location_str)
    
    # Join all parts and preprocess
    combined_text = ' '.join(filter(None, text_parts))
    return self._preprocess_text(combined_text)
</code></pre>
        <strong>Feature Components:</strong>
        <ol>
            <li>Name (weighted 3x)</li>
            <li>Description</li>
            <li>Location information</li>
        </ol>
        <h4>6. Training Data Preparation</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def prepare_training_data(self, df: pd.DataFrame, output_dir: str) -> Dict[str, str]:
    logging.info("Preparing data for training...")
    os.makedirs(output_dir, exist_ok=True)
    
    processed_data = []
    for _, memento in df.iterrows():
        memento_dict = memento.to_dict()
        text_for_ml = self._extract_text_for_ml(memento_dict)
        memento_dict['text_for_ml'] = text_for_ml
        processed_data.append(memento_dict)
    
    processed_df = pd.DataFrame(processed_data)
    output_path = os.path.join(output_dir, "user_mementos_processed.csv")
    processed_df.to_csv(output_path, index=False)
    
    return {"processed_data": output_path}
</code></pre>
        <strong>Process Flow:</strong>
        <ol>
            <li>Create output directory</li>
            <li>Process each memento</li>
            <li>Extract ML features</li>
            <li>Save processed data</li>
        </ol>
        <h4>7. Main Execution Flow</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def main():
    # Initialize data loader with paths
    loader = MementoDataLoader(
        categories_path="memento_categories.json",
        tags_path="memento_tags.json",
        durations_path="memento_durations.json",
        firebase_credentials_path="config/serviceAccountKey.json"
    )
    
    # Create output directory
    output_dir = "ml_pipeline/output/step1_data_processing/processed_data"
    os.makedirs(output_dir, exist_ok=True)
    
    # Load user mementos from Firebase
    logging.info("Loading user mementos from Firebase...")
    user_mementos = loader.load_from_firebase(limit=1000)
    
    if user_mementos.empty:
        logging.error("No user mementos found in Firebase")
        return
    
    logging.info(f"Loaded {len(user_mementos)} user mementos from Firebase")
    
    # Process the data
    processed_data = loader.prepare_training_data(user_mementos, output_dir)
</code></pre>
        <h3>Input/Output Files</h3>
        <h4>Input Files:</h4>
        <ol>
            <li><code>memento_categories.json</code></li>
            <li><code>memento_tags.json</code></li>
            <li><code>memento_durations.json</code></li>
            <li><code>config/serviceAccountKey.json</code></li>
        </ol>
        <h4>Output Files:</h4>
        <ul>
            <li><code>ml_pipeline/output/step1_data_processing/processed_data/user_mementos_processed.csv</code></li>
        </ul>
        <h3>Data Flow</h3>
        <ol>
            <li>Load metadata files</li>
            <li>Initialize Firebase connection</li>
            <li>Load user mementos</li>
            <li>Process and transform data</li>
            <li>Save processed data</li>
        </ol>
        <h3>Error Handling</h3>
        <ul>
            <li>File operations</li>
            <li>Firebase connection</li>
            <li>Data processing</li>
            <li>Type conversion</li>
            <li>Empty data checks</li>
        </ul>
        <h3>Logging</h3>
        <ul>
            <li>INFO: General progress</li>
            <li>ERROR: Processing failures</li>
            <li>WARNING: Data issues</li>
            <li>DEBUG: Detailed processing</li>
        </ul>
        <h3>Dependencies</h3>
        <ul>
            <li>pandas: Data manipulation</li>
            <li>firebase_admin: Firebase integration</li>
            <li>nltk: Text processing</li>
            <li>sklearn: Data preprocessing</li>
            <li>logging: System logging</li>
            <li>json: JSON file handling</li>
            <li>os: Directory operations</li>
        </ul>
        </section>

    <footer>
        <div class="references">
            <h3>References</h3>
            <ul>
                <li><a href="https://secretnyc.co/" target="_blank">Secret NYC</a></li>
                <li><a href="https://www.amazon.com/Walk-City-Rosemary-Dawson/dp/0670749109" target="_blank">Walk the City â€“ Book by Rosemary Dawson</a></li>
                <li><a href="https://pokemongo.com/" target="_blank">PokÃ©mon Go</a></li>
                <li><a href="https://www.peek.com/gouda-south-holland-netherlands/r084xw9/gouda-gamified-tour-solve-puzzles-and-explore-hidden-spots/a03r397" target="_blank">Gouda Gamified Tour â€“ Peek</a></li>
                <li><a href="https://www.storytourist.com/about-page/" target="_blank">StoryTourist</a></li>
                <li><a href="https://firaahda.medium.com/kresna-a-game-and-cultural-tourism-information-system-with-the-gamification-concept-smart-city-d19e243554d0" target="_blank">Kresna: A Game and Cultural Tourism System</a></li>
                <li><a href="https://senseable.mit.edu/" target="_blank">Senseable City Lab â€“ MIT</a></li>
                <li><a href="https://amt-lab.org/blog/2021/5/gamification-in-museums" target="_blank">Gamification in Museums â€“ AMT Lab</a></li>
                <li><a href="http://km.cx/projects/domestic-robocop" target="_blank">Domestic Robocop â€“ Keiichi Matsuda</a></li>
                <li><a href="https://vimeo.com/14294054" target="_blank">Augmented (Hyper)Reality â€“ Vimeo</a></li>
            </ul>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>





