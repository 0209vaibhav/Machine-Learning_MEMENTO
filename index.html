<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Role of Machine Learning and Computation in memento by Vaibhav Jain</title>
    <link rel="stylesheet" href="styles.css">
    <link href="https://fonts.googleapis.com/css2?family=Ink+Free&family=Roboto+Mono:wght@300;400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>
    <header>
        <div class="project-info">
            <h1>Role of Machine Learning and Computation in<br>
                <span class="memento-text">MEMENTO</span><span class="author-credit">by Vaibhav Jain</span>
            </h1>
            <p class="course-title"><a href="https://www.arch.columbia.edu/courses/10943-5078" target="_blank">Exploring Urban Data with Machine Learning</a></p>
            <p class="advisor">by <a href="https://www.arch.columbia.edu/faculty/5512-jonathan-stiles" target="_blank">Jonathan E. Stiles</a> in Spring 2025</p>
            <p class="program"><a href="https://www.arch.columbia.edu/programs/15-m-s-computational-design-practices" target="_blank">Computation Design Practices 2024-2025</a></p>
            <p class="college"><a href="https://www.arch.columbia.edu/" target="_blank">Graduate School of Architecture, Planning and Preservation, Columbia University</a></p>
        </div>
    </header>

    <section class="qr-row">
        <div class="qr-item">
            <a href="https://0209vaibhav.github.io/Machine-Learning_MEMENTO/" target="_blank">
                <img src="data/qr-codes/MEMENTO-machine learning-Vaibhav Jain.png" alt="MEMENTO Machine Learning QR">
            </a>
        </div>
        <div class="qr-item">
            <a href="https://0209vaibhav.github.io/Memento/" target="_blank">
                <img src="data/qr-codes/MEMENTO-platform-Vaibhav Jain.png" alt="MEMENTO Platform QR">
            </a>
        </div>
        <div class="qr-item">
            <a href="https://gsapp-cdp.github.io/archive/projects/2025/memento/" target="_blank">
                <img src="data/qr-codes/MEMENTO-project documentation-Vaibhav Jain.png" alt="MEMENTO Project Documentation QR">
            </a>
        </div>
    </section>

    <nav class="article-nav">
        <a href="#overview-section" class="active">Overview</a>
        <a href="#introduction-section">Introduction</a>
        <a href="#computation-section">Computation</a>
        <a href="#pipeline-section">Methodology</a>
        <a href="#detailed-pipeline-section">Detailed Pipeline</a>
    </nav>
    <section class="overview-section" id="overview-section">
        <h2>1. Overview</h2>
        <h3>What is MEMENTO?</h3>
        <img src="data/cover 2.png" alt="MEMENTO Cover" class="hero-image">
        <p>MEMENTO is a real-time platform that captures urban experiences happening across the city, aiming to prevent people from drifting into oblivion (the state of being unaware or unconscious of what is happening) and instead transforming those moments into engaging odysseys (a long and eventful or adventurous journey or experience).</p>
        <p>Unlike conventional platforms, MEMENTO invites users to look beyond the map — to notice, witness, interact, engage, record, react, and reflect on urban experiences as physical mementos, rather than merely experiencing them through virtual screens.</p>
        <p>It empowers users to discover, capture, and engage with the mementos around them during their commutes, turning everyday journeys into moments of exploration, creation, and interaction.</p>
        <p>MEMENTO serves as an interaction, intersection, and interplay between the city, its people, and their experiences — a platform:<br>
            By the people and the city,<br>
        For the people and the city,<br>
        Of the people and the city.</p>

<br>
        <h3>Overview of the Computation tools, methods and Machine Learning Pipeline in MEMENTO</h3>
        <img src="data/mementos-categories,tags duration.png" alt="MEMENTO - the platform" class="section-image">
        <p>The Machine Learning pipeline for public mementos in MEMENTO is designed to automate the classification and tagging of public content sourced from platforms such as Secret NYC, Reddit, NYC Bucket List, Newsbreak, and more. The objective is to replace rule-based keyword matching with a robust multi-label classification model that leverages existing user-generated mementos as training data.</p>
        <p>The pipeline consists of three primary models — Category Classification, Tag Prediction, and Duration Estimation — each trained using supervised learning techniques. Logistic Regression with One-vs-Rest strategy and Random Forest classifiers are employed to predict relevant categories and multiple tags, while Decision Trees handle ordinal duration estimation. Text data undergoes preprocessing, including tokenization, stop word removal, and TF-IDF vectorization to convert descriptions into feature vectors suitable for model training.</p>
        <p>By implementing this ML pipeline, MEMENTO enhances the consistency and accuracy of content classification, enabling the platform to transform unstructured public content into structured, contextually enriched mementos that align with its existing taxonomy.</p>
    </section>

    <section class="introduction-section" id="introduction-section">
        <h2>2. Introduction</h2>
        <p>MEMENTO is not just a platform — it's a computational ecosystem that leverages a wide spectrum of tools, methods, and data-driven processes to transform everyday urban experiences into interactive, real-time narratives. It integrates multiple computational layers, each playing a distinct role in capturing, analyzing, and visualizing the city's overlooked moments.</p>

        <h3>Computational Framework</h3>
        <p>MEMENTO's computational framework is divided into two core sections:</p>

        <div class="framework-grid">
            <div class="framework-section">
                <h4>Front End</h4>
                <p>The user-facing web-app interface that brings urban experiences to life through:</p>
                <ul>
                    <li><strong>Web-App Creation:</strong> User profiles, memento capture forms, and dynamic content rendering.</li>
                    <li><strong>Geospatial Mapping:</strong> Mapping mementos in real time using Mapbox and Google Maps API.</li>
                    <li><strong>Data Visualization:</strong> Creating interactive, data-rich maps using D3.js, highlighting patterns and clusters.</li>
                    <li><strong>Interactive Mapping:</strong> User-controlled filters, radius selectors, and category-based memento discovery.</li>
                    <li><strong>Explorer Profile Creation:</strong> User profiles that evolve through collected mementos, creating personalized urban journeys.</li>
                    <li><strong>User Interaction & Engagement:</strong> Filters, recommendations, and curated lists driven by user behavior.</li>
                </ul>
            </div>

            <div class="framework-section">
                <h4>Back End</h4>
                <p>The computational backbone that processes, stores, and structures data using:</p>
                <ul>
                    <li><strong>Firebase Cloud Storage:</strong> Real-time data storage for media, text, and location data.</li>
                    <li><strong>Machine Learning Models:</strong> Predictive analysis for recommended mementos based on user behavior and sentiment analysis.</li>
                    <li><strong>Data Structuring & Input Mapping:</strong> Categorizing mementos by type, tag, duration — transforming raw inputs into structured data.</li>
                    <li><strong>Memento Analysis & Assignment:</strong> Algorithms assign memento categories, tags, and durations based on user inputs and contextual data.</li>
                    <li><strong>Google Maps API:</strong> Geolocation data is layered onto dynamic maps, visualizing where experiences occur and how they're clustered.</li>
                    <li><strong>Public Data Scraping:</strong> Integrating public datasets from online platforms to supplement user-generated mementos with real-time urban events.</li>
                </ul>
            </div>
        </div>

        <div class="framework-summary">
            <p>Together, these front-end and back-end components create a cohesive computational ecosystem that transforms urban experiences into interactive, real-time narratives, making the city's overlooked moments discoverable and engaging.</p>
        </div>
    </section>

    <section class="computation-section" id="computation-section">
        <h2>3. Role of Computation in MEMENTO</h2>
        <h3>Computational Workflow</h3>
        <p>MEMENTO's computational workflow is built around three interconnected processes that form the backbone of the platform's functionality. These processes work in harmony to create a seamless experience for users, enabling them to capture, discover, and engage with urban experiences in real-time. The workflow integrates both front-end user interactions and back-end data processing to maintain a dynamic and responsive system.</p>

        <div class="workflow-images">
            <div class="workflow-image-caption-group">
                <img src="data/workflow/workflow-0.jpg" alt="MEMENTO Core actions" class="workflow-image">
                <p class="workflow-caption">A comprehensive visualization of the MEMENTO platform's computational workflow, illustrating the flow of memento datasets from generation to visualization to exploration, forming the core interaction model of the platform.</p>
            </div>

            <div class="workflow-steps-description">
                <h4>Creation of User Mementos:</h4>
                <p>Users capture real-time urban experiences by uploading media, adding text reflections, and tagging location data. Each memento is categorized using predefined categories, tags, and durations, creating a structured dataset of personal urban moments.</p>
    
                <h4>Creation of Public Mementos:</h4>
                <p>Public mementos are generated through data scraping from online platforms and public datasets. Machine learning methods are used to process and structure this data in real time, aligning it with the MEMENTO format for seamless integration with user-generated content.</p>
    
                <h4>Mementos on MEMENTO:</h4>
                <p>All mementos — both user-generated and public — are populated on the interactive map. Each memento is visualized with geolocation, media, timestamp, name, description, category, tags, and duration. The result is a dynamic map that acts as a real-time playground of urban experiences, accessible and discoverable for all users.</p>
    
                <h4>Exploration of Mementos:</h4>
                <p>Users can explore mementos using various filters and settings. The map allows filtering by categories, tags, duration, distance, and proximity, enabling users to discover nearby mementos, trending content, and curated experiences based on their interests and current location.</p>
    
                <h4>Curation of Mementos:</h4>
                <p>Personalized recommendations are generated based on user profile data, interests, and interaction history. Curated lists include daily mementos, trending mementos, recommended mementos, and mementos located within the user's commuting range, creating a tailored discovery experience for each user.</p>
            </div>

            <h3>Computational Workflow</h3>
        <p>MEMENTO's computational workflow is built around three interconnected processes that form the backbone of the platform's functionality. These processes work in harmony to create a seamless experience for users, enabling them to capture, discover, and engage with urban experiences in real-time. The workflow integrates both front-end user interactions and back-end data processing to maintain a dynamic and responsive system.</p>
            <div class="workflow-image-caption-group">
                <img src="data/workflow/workflow-1.jpg" alt="MEMENTO Workflow Diagram" class="workflow-image">
                <p class="workflow-caption">A detailed diagram of the MEMENTO workflow, showing the flow of memento datasets from generation to visualization to exploration, forming the core interaction model of the platform.</p>
            </div>
            <div class="workflow-image-caption-group">
                <img src="data/workflow/workflow-2.jpg" alt="MEMENTO Architecture Overview" class="workflow-image">
                <p class="workflow-caption">A comprehensive overview of the MEMENTO platform's computational architecture, illustrating the flow of memento datasets from generation to visualization to exploration, forming the core interaction model of the platform.</p>
            </div>
        </div>



    </section>

    <section class="pipeline-section" id="pipeline-section">
        <h2>Methodology</h2>
        <p>The MEMENTO ML pipeline is designed as a modular, five-step system that transforms raw public content into well-categorized, ML-enhanced mementos. Each step in the pipeline serves a specific purpose and contributes to the overall goal of automated content classification and enrichment.</p>

        <div class="pipeline-diagram">
            <div class="pipeline-steps-container">
                <div class="pipeline-step" data-step="1">
                    <div class="step-number">1</div>
                    <div class="step-content">
                        <h4>🔄 Data Processing</h4>
                        <p>Transform raw user mementos into standardized datasets</p>
                    </div>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step" data-step="2">
                    <div class="step-number">2</div>
                    <div class="step-content">
                        <h4>⚙️ Data Preparation</h4>
                        <p>Prepare data for model training</p>
                    </div>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step" data-step="3">
                    <div class="step-number">3</div>
                    <div class="step-content">
                        <h4>🧠 Model Training</h4>
                        <p>Train specialized classification models</p>
                    </div>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step" data-step="4">
                    <div class="step-number">4</div>
                    <div class="step-content">
                        <h4>🌐 Data Scraping</h4>
                        <p>Collect and process public content</p>
                    </div>
                </div>
                <div class="pipeline-arrow">→</div>
                <div class="pipeline-step" data-step="5">
                    <div class="step-number">5</div>
                    <div class="step-content">
                        <h4>✨ Processing & Classification</h4>
                        <p>Apply models to classify content</p>
                    </div>
                </div>
            </div>
            <div class="pipeline-details">
                <div class="step-details" data-step="1">
                    <h3>🔄 Step 1: Data Processing</h3>
                    <p>The initial step focuses on transforming raw user mementos into a standardized dataset suitable for machine learning. This step includes:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>📥 1. Data Collection and Standardization</h4>
                            <ul>
                                <li>Reading raw memento data from JSON files</li>
                                <li>Standardizing field names and data formats</li>
                                <li>Handling missing values and data inconsistencies</li>
                                <li>Implementing data validation checks</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>🧬 2. Feature Extraction</h4>
                            <ul>
                                <li>Processing text fields (title, description, location)</li>
                                <li>Extracting temporal information</li>
                                <li>Standardizing date formats</li>
                                <li>Handling special characters and formatting</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>✅ 3. Quality Control</h4>
                            <ul>
                                <li>Validating data integrity</li>
                                <li>Checking for required fields</li>
                                <li>Ensuring consistent data types</li>
                                <li>Generating processing statistics</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="2">
                    <h3>⚙️ Step 2: Data Preparation</h3>
                    <p>This step prepares the processed data for model training by:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>🪓 1. Data Splitting</h4>
                            <ul>
                                <li>Creating training and validation sets</li>
                                <li>Maintaining balanced category distribution</li>
                                <li>Preserving data integrity</li>
                                <li>Implementing stratified sampling</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>🛠️ 2. Feature Engineering</h4>
                            <ul>
                                <li>Creating text feature matrices</li>
                                <li>Implementing TF-IDF vectorization</li>
                                <li>Handling categorical variables</li>
                                <li>Preparing label encoders</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>🧹 3. Data Preprocessing</h4>
                            <ul>
                                <li>Text cleaning and normalization</li>
                                <li>Feature scaling</li>
                                <li>Handling missing values</li>
                                <li>Preparing multi-label formats</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="3">
                    <h3>🧠 Step 3: Model Training</h3>
                    <p>The pipeline implements three specialized models for different classification tasks:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>🌲 1. Category Classification Model</h4>
                            <ul>
                                <li>Type: Random Forest Classifier</li>
                                <li>Features: Title, description, location</li>
                                <li>Output: Category predictions with confidence scores</li>
                                <li>Parameters: n_estimators=100, max_depth=10</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>🏷️ 2. Tags Prediction Model</h4>
                            <ul>
                                <li>Type: Multi-label Classification</li>
                                <li>Features: Title, description, location</li>
                                <li>Output: Multiple tag predictions</li>
                                <li>Parameters: threshold=0.3</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>⏳ 3. Duration Estimation Model</h4>
                            <ul>
                                <li>Type: Decision Tree Classifier</li>
                                <li>Features: Title, description, location</li>
                                <li>Output: Duration predictions</li>
                                <li>Parameters: max_depth=5</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="4">
                    <h3>🌐 Step 4: Data Scraping</h3>
                    <p>This step collects and processes public content:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>🌐 1. Web Scraping</h4>
                            <ul>
                                <li>Target: Secret NYC website</li>
                                <li>Content types: Articles, events, locations</li>
                                <li>Extraction methods: BeautifulSoup4</li>
                                <li>Rate limiting and error handling</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>📝 2. Content Processing</h4>
                            <ul>
                                <li>Text extraction and cleaning</li>
                                <li>Date parsing and standardization</li>
                                <li>Location extraction</li>
                                <li>Duration estimation</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>🔍 3. Data Validation</h4>
                            <ul>
                                <li>Content quality checks</li>
                                <li>Required field validation</li>
                                <li>Format standardization</li>
                                <li>Error logging</li>
                            </ul>
                        </div>
                    </div>
                </div>
                <div class="step-details" data-step="5">
                    <h3>✨ Step 5: Data Processing and Classification</h3>
                    <p>The final step applies the trained models to classify scraped content:</p>
                    <div class="pipeline-detail-row">
                        <div class="pipeline-detail-column">
                            <h4>🤖 1. Model Application</h4>
                            <ul>
                                <li>Loading trained models</li>
                                <li>Text preprocessing</li>
                                <li>Feature extraction</li>
                                <li>Prediction generation</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>🛡️ 2. Quality Control</h4>
                            <ul>
                                <li>Confidence threshold checks</li>
                                <li>Prediction validation</li>
                                <li>Error handling</li>
                                <li>Report generation</li>
                            </ul>
                        </div>
                        <div class="pipeline-detail-column">
                            <h4>📦 3. Output Generation</h4>
                            <ul>
                                <li>Creating processed mementos</li>
                                <li>Adding predictions and confidence scores</li>
                                <li>Generating processing reports</li>
                                <li>Saving results in multiple formats</li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="detailed-pipeline-section" id="detailed-pipeline-section">
        <h2>Detailed Pipeline Implementation and Methodology</h2>
        <h3>Overview</h3>
        <p>The MEMENTO ML pipeline is implemented as a modular Python system, with each step building upon the previous one to transform raw content into ML-enhanced mementos. This section provides a detailed technical breakdown of each step, including implementation details, code examples, and data flow.</p>

        <hr>
        <h2>Step 1: Data Loading and Preparation <span style="font-size:0.7em; font-weight:normal;">(step1_data_loader.py)</span></h2>
        <h3>Overview</h3>
        <p>The first step of the MEMENTO ML pipeline focuses on loading user mementos from Firebase and preparing them for machine learning training. This step is crucial for establishing the foundation of our ML pipeline by ensuring data quality and proper formatting.</p>
        <h3>Purpose</h3>
        <ul>
            <li>Load user mementos from Firebase</li>
            <li>Process and standardize the data</li>
            <li>Prepare features for ML training</li>
            <li>Save processed data for subsequent steps</li>
        </ul>
        <h3>Implementation Details</h3>
        <h4>1. Class Structure and Initialization</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">class MementoDataLoader:
    def __init__(self, 
                 categories_path: str = None,
                 tags_path: str = None,
                 durations_path: str = None,
                 firebase_credentials_path: str = None):
        self.categories = {}
        self.tags = {}
        self.durations = {}
        self.db = None
        self.lemmatizer = WordNetLemmatizer()
        self.stop_words = set(stopwords.words('english'))
</code></pre>
        <strong>Components:</strong>
        <ul>
            <li>Categories dictionary: Stores category mappings</li>
            <li>Tags dictionary: Stores tag information</li>
            <li>Durations dictionary: Stores duration configurations</li>
            <li>Firebase database connection</li>
            <li>NLTK components for text processing</li>
        </ul>
        <strong>Dependencies:</strong>
        <ul>
            <li>NLTK (Natural Language Toolkit)</li>
            <li>Firebase Admin SDK</li>
            <li>Pandas</li>
            <li>Logging module</li>
        </ul>
        <h4>2. Metadata Loading</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def load_categories(self, categories_path: str):
    logging.info(f"Loading categories from {categories_path}")
    with open(categories_path, "r", encoding="utf-8") as f:
        self.categories = json.load(f)
    logging.info(f"Loaded {len(self.categories)} categories")

def load_tags(self, tags_path: str) -> List[str]:
    logging.info(f"Loading tags from {tags_path}")
    with open(tags_path, "r", encoding="utf-8") as f:
        tags_data = json.load(f)
        tags = [tag["name"] for tag in tags_data]
    logging.info(f"Loaded {len(tags)} tags")
    return tags

def load_durations(self, durations_path: str):
    logging.info(f"Loading durations from {durations_path}")
    with open(durations_path, "r", encoding="utf-8") as f:
        self.durations = json.load(f)
    logging.info(f"Loaded {len(self.durations)} durations")
</code></pre>
        <strong>Process:</strong>
        <ol>
            <li>Read JSON files containing metadata</li>
            <li>Validate file format and content</li>
            <li>Store metadata in class attributes</li>
            <li>Log loading statistics</li>
        </ol>
        <strong>Input Files:</strong>
        <ul>
            <li><code>memento_categories.json</code>: Category definitions</li>
            <li><code>memento_tags.json</code>: Tag definitions</li>
            <li><code>memento_durations.json</code>: Duration definitions</li>
        </ul>
        <div class="json-scroll-lists-wrapper">
            <div class="json-scroll-list">
                <h4>Categories <span style="font-size:0.9em; color:#888;">(memento_categories.json)</span></h4>
                <ul>
                    <li>🏛️ Architecture <span class="json-id">(architecture)</span></li>
                    <li>🌿 Urban Nature <span class="json-id">(urban-nature)</span></li>
                    <li>🌈 Sky & Weather <span class="json-id">(sky-weather)</span></li>
                    <li>🎭 Cultural Spotlight <span class="json-id">(cultural)</span></li>
                    <li>🎧 Mood & Music <span class="json-id">(mood-music)</span></li>
                    <li>🐾 Creature Sighting <span class="json-id">(creature)</span></li>
                    <li>🍴 Street Food <span class="json-id">(street-food)</span></li>
                    <li>👥 Social Gathering <span class="json-id">(social)</span></li>
                    <li>⚽ Sport in Action <span class="json-id">(sport)</span></li>
                    <li>✍️ Poetic Reflection <span class="json-id">(poetic)</span></li>
                    <li>💡 Urban Folklore <span class="json-id">(folklore)</span></li>
                    <li>🏗️ City in Transition <span class="json-id">(transition)</span></li>
                    <li>⚠️ Unpleasant Spot <span class="json-id">(unpleasant)</span></li>
                    <li>👥 Public Event <span class="json-id">(public-event)</span></li>
                    <li>🛍️ Pop-Up Culture <span class="json-id">(popup-culture)</span></li>
                    <li>🎮 Play & Participation <span class="json-id">(playful)</span></li>
                    <li>🎓 City Learning <span class="json-id">(learning)</span></li>
                    <li>🕊️ Tranquil Corners <span class="json-id">(tranquil)</span></li>
                    <li>🧪 Experimental Urbanism <span class="json-id">(experimental)</span></li>
                    <li>🗂️ Other <span class="json-id">(other)</span></li>
                </ul>
            </div>
            <div class="json-scroll-list">
                <h4>Tags <span style="font-size:0.9em; color:#888;">(memento_tags.json)</span></h4>
                <ul>
                    <li>🌀 Ephemeral <span class="json-id">(ephemeral)</span></li>
                    <li>📍 Unmapped <span class="json-id">(unmapped)</span></li>
                    <li>🧬 Niche/Cult <span class="json-id">(niche)</span></li>
                    <li>💫 Emotionally Charged <span class="json-id">(emotional)</span></li>
                    <li>🕵️ Hidden Gem <span class="json-id">(hidden)</span></li>
                    <li>🎭 Unexpected Encounter <span class="json-id">(unexpected)</span></li>
                    <li>🪞 Reflective <span class="json-id">(reflective)</span></li>
                    <li>💔 Unpleasant Truth <span class="json-id">(unpleasant)</span></li>
                    <li>⏳ Once-in-a-While <span class="json-id">(rare)</span></li>
                    <li>🔄 Recurring Ritual <span class="json-id">(recurring)</span></li>
                    <li>🧃 Local Flavor <span class="json-id">(local)</span></li>
                    <li>💃 Performative <span class="json-id">(performative)</span></li>
                    <li>👀 Blink and You Miss It <span class="json-id">(blink)</span></li>
                    <li>🧲 Highly Social <span class="json-id">(social-heavy)</span></li>
                    <li>🌃 Nightlife Pulse <span class="json-id">(nightlife)</span></li>
                    <li>🧳 Touristy Yet Fun <span class="json-id">(touristy)</span></li>
                    <li>🧼 Over-Polished <span class="json-id">(clean-cut)</span></li>
                    <li>🐣 First-Time Friendly <span class="json-id">(beginner)</span></li>
                    <li>🏙️ Iconic Landmark <span class="json-id">(iconic)</span></li>
                    <li>🗂️ Other <span class="json-id">(other)</span></li>
                </ul>
            </div>
            <div class="json-scroll-list">
                <h4>Durations <span style="font-size:0.9em; color:#888;">(memento_durations.json)</span></h4>
                <ul>
                    <li>⚡ 15 Minutes <span class="json-id">(15min)</span></li>
                    <li>⏱️ 1 Hour <span class="json-id">(1hr)</span></li>
                    <li>⌛ 1-3 Hours <span class="json-id">(1-3hrs)</span></li>
                    <li>🌅 3-6 Hours <span class="json-id">(3-6hrs)</span></li>
                    <li>🌞 6-12 Hours <span class="json-id">(6-12hrs)</span></li>
                    <li>🌙 A Day <span class="json-id">(24hrs)</span></li>
                    <li>📅 A Week <span class="json-id">(1-week)</span></li>
                    <li>📆 A Month <span class="json-id">(1-month)</span></li>
                    <li>🔄 A Season <span class="json-id">(1-season)</span></li>
                    <li>📅 A Year <span class="json-id">(1-year)</span></li>
                    <li>♾️ Eternal <span class="json-id">(eternal)</span></li>
                    <li>🗂️ Other <span class="json-id">(other)</span></li>
                </ul>
            </div>
        </div>
        <h4>3. Firebase Integration</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def _initialize_firebase(self):
    try:
        cred = credentials.Certificate(self.firebase_credentials_path)
        firebase_admin.initialize_app(cred)
        self.db = firestore.client()
        logging.info("Firebase initialized successfully")
    except Exception as e:
        logging.error(f"Failed to initialize Firebase: {e}")

def load_from_firebase(self, limit=1000):
    try:
        logging.info(f"Loading up to {limit} mementos from Firebase")
        mementos_ref = self.db.collection("mementos").limit(limit)
        mementos = mementos_ref.get()
        
        memento_list = []
        for doc in mementos:
            memento_data = doc.to_dict()
            memento_data['id'] = doc.id
            memento_list.append(memento_data)
        
        return pd.DataFrame(memento_list)
    except Exception as e:
        logging.error(f"Error loading mementos from Firebase: {str(e)}")
        raise
</code></pre>
        <strong>Features:</strong>
        <ul>
            <li>Secure credential management</li>
            <li>Error handling and logging</li>
            <li>Connection state tracking</li>
            <li>Data retrieval with limit</li>
            </ul>
        <h4>4. Text Preprocessing</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def _preprocess_text(self, text: str) -> str:
    if not isinstance(text, str):
        text = str(text)
    
    # Convert to lowercase
    text = text.lower()
    
    # Remove special characters and digits
    text = re.sub(r'[^a-z\s]', ' ', text)
    
    # Remove extra whitespace
    text = ' '.join(text.split())
    
    return text
</code></pre>
        <strong>Processing Steps:</strong>
        <ol>
            <li>Type conversion to string</li>
            <li>Lowercase conversion</li>
            <li>Special character removal</li>
            <li>Whitespace normalization</li>
        </ol>
        <h4>5. Feature Extraction</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def _extract_text_for_ml(self, memento: Dict) -> str:
    text_parts = []
    
    # Add name with higher weight (repeat 3 times)
    name = memento.get('name', '')
    text_parts.extend([name] * 3)
    
    # Add description
    description = memento.get('description', '')
    text_parts.append(description)
    
    # Add location name if available
    location = memento.get('location', {})
    if isinstance(location, dict):
        location_str = str(location)
        text_parts.append(location_str)
    
    # Join all parts and preprocess
    combined_text = ' '.join(filter(None, text_parts))
    return self._preprocess_text(combined_text)
</code></pre>
        <strong>Feature Components:</strong>
        <ol>
            <li>Name (weighted 3x)</li>
            <li>Description</li>
            <li>Location information</li>
        </ol>
        <h4>6. Training Data Preparation</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def prepare_training_data(self, df: pd.DataFrame, output_dir: str) -> Dict[str, str]:
    logging.info("Preparing data for training...")
    os.makedirs(output_dir, exist_ok=True)
    
    processed_data = []
    for _, memento in df.iterrows():
        memento_dict = memento.to_dict()
        text_for_ml = self._extract_text_for_ml(memento_dict)
        memento_dict['text_for_ml'] = text_for_ml
        processed_data.append(memento_dict)
    
    processed_df = pd.DataFrame(processed_data)
    output_path = os.path.join(output_dir, "user_mementos_processed.csv")
    processed_df.to_csv(output_path, index=False)
    
    return {"processed_data": output_path}
</code></pre>
        <strong>Process Flow:</strong>
        <ol>
            <li>Create output directory</li>
            <li>Process each memento</li>
            <li>Extract ML features</li>
            <li>Save processed data</li>
        </ol>
        <h4>7. Main Execution Flow</h4>
        <strong>Code:</strong>
        <pre><code class="language-python">def main():
    # Initialize data loader with paths
    loader = MementoDataLoader(
        categories_path="memento_categories.json",
        tags_path="memento_tags.json",
        durations_path="memento_durations.json",
        firebase_credentials_path="config/serviceAccountKey.json"
    )
    
    # Create output directory
    output_dir = "ml_pipeline/output/step1_data_processing/processed_data"
    os.makedirs(output_dir, exist_ok=True)
    
    # Load user mementos from Firebase
    logging.info("Loading user mementos from Firebase...")
    user_mementos = loader.load_from_firebase(limit=1000)
    
    if user_mementos.empty:
        logging.error("No user mementos found in Firebase")
        return
    
    logging.info(f"Loaded {len(user_mementos)} user mementos from Firebase")
    
    # Process the data
    processed_data = loader.prepare_training_data(user_mementos, output_dir)
</code></pre>
        <h3>Input/Output Files</h3>
        <h4>Input Files:</h4>
        <ol>
            <li><code>memento_categories.json</code></li>
            <li><code>memento_tags.json</code></li>
            <li><code>memento_durations.json</code></li>
            <li><code>config/serviceAccountKey.json</code></li>
        </ol>
        <h4>Output Files:</h4>
        <ul>
            <li><code>ml_pipeline/output/step1_data_processing/processed_data/user_mementos_processed.csv</code></li>
        </ul>
        <h3>Data Flow</h3>
        <ol>
            <li>Load metadata files</li>
            <li>Initialize Firebase connection</li>
            <li>Load user mementos</li>
            <li>Process and transform data</li>
            <li>Save processed data</li>
        </ol>
        <h3>Error Handling</h3>
        <ul>
            <li>File operations</li>
            <li>Firebase connection</li>
            <li>Data processing</li>
            <li>Type conversion</li>
            <li>Empty data checks</li>
            </ul>
        <h3>Logging</h3>
        <ul>
            <li>INFO: General progress</li>
            <li>ERROR: Processing failures</li>
            <li>WARNING: Data issues</li>
            <li>DEBUG: Detailed processing</li>
            </ul>
        <h3>Dependencies</h3>
        <ul>
            <li>pandas: Data manipulation</li>
            <li>firebase_admin: Firebase integration</li>
            <li>nltk: Text processing</li>
            <li>sklearn: Data preprocessing</li>
            <li>logging: System logging</li>
            <li>json: JSON file handling</li>
            <li>os: Directory operations</li>
            </ul>
        </section>

    <footer>
        <div class="references">
            <h3>References</h3>
            <ul>
                <li><a href="https://secretnyc.co/" target="_blank">Secret NYC</a></li>
                <li><a href="https://www.amazon.com/Walk-City-Rosemary-Dawson/dp/0670749109" target="_blank">Walk the City – Book by Rosemary Dawson</a></li>
                <li><a href="https://pokemongo.com/" target="_blank">Pokémon Go</a></li>
                <li><a href="https://www.peek.com/gouda-south-holland-netherlands/r084xw9/gouda-gamified-tour-solve-puzzles-and-explore-hidden-spots/a03r397" target="_blank">Gouda Gamified Tour – Peek</a></li>
                <li><a href="https://www.storytourist.com/about-page/" target="_blank">StoryTourist</a></li>
                <li><a href="https://firaahda.medium.com/kresna-a-game-and-cultural-tourism-information-system-with-the-gamification-concept-smart-city-d19e243554d0" target="_blank">Kresna: A Game and Cultural Tourism System</a></li>
                <li><a href="https://senseable.mit.edu/" target="_blank">Senseable City Lab – MIT</a></li>
                <li><a href="https://amt-lab.org/blog/2021/5/gamification-in-museums" target="_blank">Gamification in Museums – AMT Lab</a></li>
                <li><a href="http://km.cx/projects/domestic-robocop" target="_blank">Domestic Robocop – Keiichi Matsuda</a></li>
                <li><a href="https://vimeo.com/14294054" target="_blank">Augmented (Hyper)Reality – Vimeo</a></li>
            </ul>
        </div>
    </footer>

    <script src="script.js"></script>
</body>
</html>





